% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{wangLFRecognition_ECCV2016}
T.-C. Wang, J.-Y. Zhu, E.~Hiroaki, M.~Chandraker, A.~A. Efros, and R.~Ramamoorthi, ``A {{4D}} light-field dataset and {{CNN}} architectures for material recognition,'' in \emph{European {{Conference}} on {{Computer Vision}}}.\hskip 1em plus 0.5em minus 0.4em\relax {Springer}, 2016, pp. 121--138.

\bibitem{luLFRecognition_2019}
Z.~Lu, H.~W.~F. Yeung, Q.~Qu, Y.~Y. Chung, X.~Chen, and Z.~Chen, ``Improved image classification with {{4D}} light-field and interleaved convolutional neural network,'' \emph{Tools and Applications}, vol.~78, no.~20, pp. 29\,211--29\,227, Oct. 2019.

\bibitem{yucer2016efficient}
K.~Y{\"u}cer, A.~Sorkine-Hornung, O.~Wang, and O.~Sorkine-Hornung, ``Efficient 3d object segmentation from densely sampled light fields with applications to 3d reconstruction,'' \emph{ACM Transactions on Graphics (TOG)}, vol.~35, no.~3, p.~22, 2016.

\bibitem{heberUshapeICCV2017}
S.~Heber, W.~Yu, and T.~Pock, ``Neural {{EPI}}-{{Volume Networks}} for {{Shape}} from {{Light Field}},'' in \emph{Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}}, 2017, pp. 2271--2279.

\bibitem{wangOcclusionawareDepthEstimation2015}
T.-C. Wang, A.~A. Efros, and R.~Ramamoorthi, ``Occlusion-aware depth estimation using light-field cameras,'' in \emph{Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}}, 2015, pp. 3487--3495.

\bibitem{chaoSubFocal_TCI2023}
W.~Chao, X.~Wang, Y.~Wang, G.~Wang, and F.~Duan, ``Learning sub-pixel disparity distribution for light field depth estimation,'' \emph{IEEE Transactions on Computational Imaging}, vol.~9, pp. 1126--1138, 2023.

\bibitem{ding_TCI2023}
Y.~Ding, Z.~Chen, Y.~Ji, J.~Yu, and J.~Ye, ``Light field-based underwater 3d reconstruction via angular resampling,'' \emph{IEEE Transactions on Computational Imaging}, 2023.

\bibitem{shengLFSaliency_ICASSP2016}
H.~Sheng, S.~Zhang, X.~Liu, and Z.~Xiong, ``Relative location for light field saliency detection,'' in \emph{2016 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2016, pp. 1631--1635.

\bibitem{zhangLFNet_TIP2020}
M.~Zhang, W.~Ji, Y.~Piao, J.~Li, Y.~Zhang, S.~Xu, and H.~Lu, ``Lfnet: {{Light}} field fusion network for salient object detection,'' \emph{IEEE Transactions on Image Processing}, vol.~29, pp. 6276--6287, 2020.

\bibitem{chen_TMM2023}
G.~Chen, H.~Fu, T.~Zhou, G.~Xiao, K.~Fu, Y.~Xia, and Y.~Zhang, ``Fusion-embedding siamese network for light field salient object detection,'' \emph{IEEE Transactions on Multimedia}, 2023.

\bibitem{verinaz_TCI2022}
H.~Verinaz-Jadan, P.~Song, C.~L. Howe, A.~J. Foust, and P.~L. Dragotti, ``Shift-invariant-subspace discretization and volume reconstruction for light field microscopy,'' \emph{IEEE Transactions on Computational Imaging}, vol.~8, pp. 286--301, 2022.

\bibitem{verinaz_TCI2023}
H.~Verinaz-Jadan, C.~L. Howe, P.~Song, F.~Lesept, J.~Kittler, A.~J. Foust, and P.~L. Dragotti, ``Physics-based deep learning for imaging neuronal activity via two-photon and light field microscopy,'' \emph{IEEE Transactions on Computational Imaging}, 2023.

\bibitem{levoy2006light}
M.~Levoy, R.~Ng, A.~Adams, M.~Footer, and M.~Horowitz, ``Light field microscopy,'' in \emph{Acm Siggraph 2006 Papers}, 2006, pp. 924--934.

\bibitem{raghavendraLFFace_TIP2015}
R.~Raghavendra, K.~B. Raja, and C.~Busch, ``Presentation attack detection for face recognition using light field camera,'' \emph{IEEE Transactions on Image Processing}, vol.~24, no.~3, pp. 1060--1075, 2015.

\bibitem{jiLFHOG_ICIP2016}
Z.~Ji, H.~Zhu, and Q.~Wang, ``{{LFHOG}}: {{A}} discriminative descriptor for live face detection from light field image,'' in \emph{2016 {{IEEE}} International Conference on Image Processing ({{ICIP}})}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2016, pp. 1474--1478.

\bibitem{wilburn2004high}
B.~Wilburn, N.~Joshi, V.~Vaish, M.~Levoy, and M.~Horowitz, ``High-speed videography using a dense camera array,'' in \emph{Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.}, vol.~2.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2004, pp. II--II.

\bibitem{wilburn2005high}
B.~Wilburn, N.~Joshi, V.~Vaish, E.-V. Talvala, E.~Antunez, A.~Barth, A.~Adams, M.~Horowitz, and M.~Levoy, ``High performance imaging using large camera arrays,'' in \emph{ACM Transactions on Graphics (TOG)}, vol.~24, no.~3.\hskip 1em plus 0.5em minus 0.4em\relax ACM, 2005, pp. 765--776.

\bibitem{Raytrix}
Raytrix, ``3d light field camera technology,'' https://raytrix.de/, 2020, accessed: 2023-06-10.

\bibitem{Lytro}
{Wikipedia contributors}, ``Lytro --- {Wikipedia}{,} the free encyclopedia,'' https://w.wiki/7G9s, 2020, accessed: 2023-06-10.

\bibitem{GoogleLF}
P.~Debevec, ``Experimenting with light fields,'' https://blog.google/products/google-ar-vr/experimenting-light-fields/, 2018, accessed: 2023-06-10.

\bibitem{yeungSAS_LFSR2019}
H.~W.~F. Yeung, J.~Hou, X.~Chen, J.~Chen, Z.~Chen, and Y.~Y. Chung, ``Light {{Field Spatial Super}}-{{Resolution Using Deep Efficient Spatial}}-{{Angular Separable Convolution}},'' \emph{IEEE Transactions on Image Processing}, vol.~28, no.~5, pp. 2319--2330, 2019.

\bibitem{wangDistgSSR_TIP2022}
Y.~Wang, L.~Wang, G.~Wu, J.~Yang, W.~An, J.~Yu, and Y.~Guo, ``Disentangling light fields for super-resolution and disparity estimation,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2022.

\bibitem{liu_TMM2022}
G.~Liu, H.~Yue, J.~Wu, and J.~Yang, ``Efficient light field angular super-resolution with sub-aperture feature learning and macro-pixel upsampling,'' \emph{IEEE Transactions on Multimedia}, 2022.

\bibitem{yeungSAS_ECCV2018}
H.~W.~F. Yeung, J.~Hou, J.~Chen, Y.~Y. Chung, and X.~Chen, ``Fast light field reconstruction with deep coarse-to-fine modeling of spatial-angular clues,'' in \emph{The European Conference on Computer Vision (ECCV)}, Sep. 2018, pp. 137--152.

\bibitem{yoon2017LFCNN}
Y.~Yoon, H.-G. Jeon, D.~Yoo, J.-Y. Lee, and I.~S. Kweon, ``Light-field image super-resolution using convolutional neural network,'' \emph{IEEE Signal Processing Letters}, vol.~24, no.~6, pp. 848--852, 2017.

\bibitem{dosovitskiyViT_arXiv2020}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit, and N.~Houlsby, ``An {{Image}} is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}},'' 2023.

\bibitem{liuSwin_ICCV2021}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin transformer: Hierarchical vision transformer using shifted windows,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 10\,012--10\,022.

\bibitem{luESRT_CVPR2022}
Z.~Lu, J.~Li, H.~Liu, C.~Huang, L.~Zhang, and T.~Zeng, ``Transformer for single image super-resolution,'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2022, pp. 457--466.

\bibitem{wanner2014variational}
S.~Wanner and B.~Goldluecke, ``Variational light field analysis for disparity estimation and super-resolution,'' \emph{IEEE transactions on pattern analysis and machine intelligence}, vol.~36, no.~3, pp. 606--619, 2014.

\bibitem{wangDPT_AAAI2022}
S.~Wang, T.~Zhou, Y.~Lu, and H.~Di, ``Detail preserving transformer for light field image super-resolution,'' in \emph{Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.}, 2022.

\bibitem{liangLFT_SPL2022}
Z.~Liang, Y.~Wang, L.~Wang, J.~Yang, and S.~Zhou, ``Light field image super-resolution with transformers,'' \emph{IEEE Signal Processing Letters}, vol.~29, pp. 563--567, 2022.

\bibitem{liangEPIT_arXiv2023}
Z.~Liang, Y.~Wang, L.~Wang, J.~Yang, S.~Zhou, and Y.~Guo, ``Learning {{Non-Local Spatial-Angular Correlation}} for {{Light Field Image Super-Resolution}},'' 2023.

\bibitem{guLAM_CVPR2021}
J.~Gu and C.~Dong, ``Interpreting {{Super-Resolution Networks}} with {{Local Attribution Maps}},'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2021, pp. 9199--9208.

\bibitem{dongSRCNN_ECCV2014}
C.~Dong, C.~C. Loy, K.~He, and X.~Tang, ``Learning a deep convolutional network for image super-resolution,'' in \emph{European Conference on Computer Vision}, vol. 8689, 2014, pp. 184--199.

\bibitem{kimVDSR_CVPR2016}
J.~Kim, J.~K. Lee, and K.~M. Lee, ``Accurate {{Image Super}}-{{Resolution Using Very Deep Convolutional Networks}},'' in \emph{{{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})}, 2016, pp. 1646--1654.

\bibitem{zhangRDN_CVPR2018}
Y.~Zhang, Y.~Tian, Y.~Kong, B.~Zhong, and Y.~Fu, ``Residual dense network for image super-resolution,'' in \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, 2018, pp. 2472--2481.

\bibitem{zhangRCAN_ECCV2018}
Y.~Zhang, K.~Li, K.~Li, L.~Wang, B.~Zhong, and Y.~Fu, ``Image super-resolution using very deep residual channel attention networks,'' in \emph{European {{Conference}} on {{Computer Vision}}}, 2018, pp. 286--301.

\bibitem{esmaeilzehi_TCI2021}
A.~Esmaeilzehi, M.~O. Ahmad, and M.~Swamy, ``Srnssi: a deep light-weight network for single image super resolution using spatial and spectral information,'' \emph{IEEE Transactions on Computational Imaging}, vol.~7, pp. 409--421, 2021.

\bibitem{wuSeeSR_arXiv2023}
R.~Wu, T.~Yang, L.~Sun, Z.~Zhang, S.~Li, and L.~Zhang, ``{{SeeSR}}: {{Towards Semantics-Aware Real-World Image Super-Resolution}},'' Nov. 2023.

\bibitem{ledigSRGAN_CVPR2017}
C.~Ledig, L.~Theis, F.~Huszar, J.~Caballero, A.~Cunningham, A.~Acosta, A.~Aitken, A.~Tejani, J.~Totz, Z.~Wang, and W.~Shi, ``Photo-{{Realistic Single Image Super}}-{{Resolution Using}} a {{Generative Adversarial Network}},'' in \emph{Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2017, pp. 4681--4690.

\bibitem{SajjadiEnhanceNet_ICCV2017}
M.~S.~M. Sajjadi, B.~Sch{\"o}lkopf, and M.~Hirsch, ``{{EnhanceNet}}: {{Single Image Super}}-{{Resolution Through Automated Texture Synthesis}},'' in \emph{{{IEEE International Conference}} on {{Computer Vision}}}, 2017, pp. 4491--4500.

\bibitem{ViT}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.}, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{chenIPT_CVPR2021}
H.~Chen, Y.~Wang, T.~Guo, C.~Xu, Y.~Deng, Z.~Liu, S.~Ma, C.~Xu, C.~Xu, and W.~Gao, ``Pre-trained image processing transformer,'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2021, pp. 12\,299--12\,310.

\bibitem{liangSwinIR_ICCV2021}
J.~Liang, J.~Cao, G.~Sun, K.~Zhang, L.~Van~Gool, and R.~Timofte, ``Swinir: {{Image}} restoration using swin transformer,'' in \emph{Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}}, 2021, pp. 1833--1844.

\bibitem{chenHAT_CVPR2023}
X.~Chen, X.~Wang, J.~Zhou, Y.~Qiao, and C.~Dong, ``Activating more pixels in image super-resolution transformer,'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2023, pp. 22\,367--22\,377.

\bibitem{zhouSRFormer_ICCV2023}
\BIBentryALTinterwordspacing
Y.~Zhou, Z.~Li, C.-L. Guo, S.~Bai, M.-M. Cheng, and Q.~Hou. {{SRFormer}}: {{Permuted Self-Attention}} for {{Single Image Super-Resolution}}. [Online]. Available: \url{http://arxiv.org/abs/2303.09735}
\BIBentrySTDinterwordspacing

\bibitem{zhangELAN_ECCV2022}
X.~Zhang, H.~Zeng, S.~Guo, and L.~Zhang, ``Efficient long-range attention network for image super-resolution,'' in \emph{Computer {{Vision}}\textendash{{ECCV}} 2022: 17th {{European Conference}}, {{Tel Aviv}}, {{Israel}}, {{October}} 23\textendash 27, 2022, {{Proceedings}}, {{Part XVII}}}.\hskip 1em plus 0.5em minus 0.4em\relax {Springer}, 2022, pp. 649--667.

\bibitem{jinLFSSRATO_2020}
J.~Jin, J.~Hou, J.~Chen, and S.~Kwong, ``Light field spatial super-resolution via deep combinatorial geometry embedding and structural consistency regularization,'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2020, pp. 2260--2269.

\bibitem{wangLfInterNet_ECCV2020}
Y.~Wang, L.~Wang, J.~Yang, W.~An, J.~Yu, and Y.~Guo, ``Spatial-angular interaction for light field image super-resolution,'' in \emph{European {{Conference}} on {{Computer Vision}}}.\hskip 1em plus 0.5em minus 0.4em\relax {Springer}, 2020, pp. 290--308.

\bibitem{liuLFIINet_TMM2021}
G.~Liu, H.~Yue, J.~Wu, and J.~Yang, ``Intra-{{Inter View Interaction Network}} for {{Light Field Image Super-Resolution}},'' \emph{IEEE Transactions on Multimedia}, vol.~25, pp. 256--266, 2021.

\bibitem{chen_TMM2021}
Y.~Chen, G.~Jiang, Z.~Jiang, M.~Yu, and Y.-S. Ho, ``Deep light field super-resolution using frequency domain analysis and semantic prior,'' \emph{IEEE Transactions on Multimedia}, vol.~24, pp. 3722--3737, 2021.

\bibitem{sun_TMM2022}
Y.~Sun, L.~Li, Z.~Li, S.~Wang, S.~Liu, and G.~Li, ``Learning a compact spatial-angular representation for light field,'' \emph{IEEE Transactions on Multimedia}, 2022.

\bibitem{huDKNet_TIM2022}
Z.~Hu, X.~Chen, H.~W.~F. Yeung, Y.~Y. Chung, and Z.~Chen, ``Texture-{{Enhanced Light Field Super-Resolution With Spatio-Angular Decomposition Kernels}},'' \emph{IEEE Transactions on Instrumentation and Measurement}, vol.~71, pp. 1--16, 2022.

\bibitem{rossi2018geometry}
M.~Rossi and P.~Frossard, ``Geometry-consistent light field super-resolution via graph-based regularization,'' \emph{IEEE Transactions on Image Processing}, vol.~27, no.~9, pp. 4207--4218, 2018.

\bibitem{ghassab_TMM2019}
V.~K. Ghassab and N.~Bouguila, ``Light field super-resolution using edge-preserved graph-based regularization,'' \emph{IEEE Transactions on Multimedia}, vol.~22, no.~6, pp. 1447--1457, 2019.

\bibitem{wangBoosting_TCI2023}
X.~Wang, Z.~Wang, W.~Huang, K.~Chen, and L.~Li, ``Boosting {{Light Field Image Super Resolution Learnt From Single-Image Prior}},'' \emph{IEEE Transactions on Computational Imaging}, 2023.

\bibitem{xiaoCutMIB_CVPR2023}
Z.~Xiao, Y.~Liu, R.~Gao, and Z.~Xiong, ``Cutmib: {{Boosting}} light field super-resolution via multi-view image blending,'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2023, pp. 1672--1682.

\bibitem{chuCPVT_arxiv2021}
X.~Chu, Z.~Tian, B.~Zhang, X.~Wang, X.~Wei, H.~Xia, and C.~Shen, ``Conditional {{Positional Encodings}} for {{Vision Transformers}},'' 2021.

\bibitem{BasicLFSR}
``Basiclfsr: Open source light field toolbox for super-resolution,'' https://github.com/ZhengyuLiang24/BasicLFSR, 2023, accessed: 2023-06-10.

\bibitem{rerabekEPFL2016}
M.~Rerábek and T.~Ebrahimi, ``New {{Light Field Image Dataset}},'' \emph{8th International Conference on Quality of Multimedia Experience (QoMEX)}, pp. 1--2, 2016.

\bibitem{honauerHCInew_ACCV2016}
K.~Honauer, O.~Johannsen, D.~Kondermann, and B.~Goldluecke, ``A dataset and evaluation methodology for depth estimation on 4d light fields,'' in \emph{Asian {{Conference}} on {{Computer Vision}}}.\hskip 1em plus 0.5em minus 0.4em\relax {Springer}, 2016, pp. 19--34.

\bibitem{wannerHCIold_VMV2013}
S.~Wanner, S.~Meister, and B.~Goldluecke, ``Datasets and benchmarks for densely sampled {{4D}} light fields.'' in \emph{Vision, {{Modelling}} and {{Visualization}} ({{VMV}})}, vol.~13, 2013, pp. 225--226.

\bibitem{lependuINRIA_TIP2018}
M.~Le~Pendu, X.~Jiang, and C.~Guillemot, ``Light field inpainting propagation via low rank matrix completion,'' \emph{IEEE Transactions on Image Processing}, vol.~27, no.~4, pp. 1981--1993, 2018.

\bibitem{vaishSTFgantry_2008}
V.~Vaish and A.~Adams, ``The (new) stanford light field archive,'' \emph{Computer Graphics Laboratory, Stanford University}, vol.~6, no.~7, p.~3, 2008.

\bibitem{limEDSR_CVPRW2017}
B.~Lim, S.~Son, H.~Kim, S.~Nah, and K.~Mu~Lee, ``Enhanced deep residual networks for single image super-resolution,'' in \emph{Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition Workshops}, 2017, pp. 136--144.

\bibitem{wangOACCNet_CVPR2022}
Y.~Wang, L.~Wang, Z.~Liang, J.~Yang, W.~An, and Y.~Guo, ``Occlusion-{{Aware Cost Constructor}} for {{Light Field Depth Estimation}},'' in \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, 2022, pp. 19\,809--19\,818.

\end{thebibliography}
